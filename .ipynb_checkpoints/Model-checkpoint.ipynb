{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import arrow\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "class PMF(object):\n",
    "    '''\n",
    "    Probabilistic Matrix Factorization\n",
    "    '''\n",
    "\n",
    "    def __init__(self, n_feature, epsilon, lam, n_epoches, n_batches):\n",
    "        self.n_feature = n_feature  # number of features\n",
    "        self.epsilon   = epsilon    # epsilon for leanring rate\n",
    "        self.lam       = lam        # lambda for L2 regularization\n",
    "\n",
    "        self.n_epoches = n_epoches  # number of epoches\n",
    "        self.n_batches = n_batches  # number of batches\n",
    "\n",
    "        self.V = None # items feature matrix\n",
    "        self.U = None # users feature matrix\n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "\n",
    "    def loss(self, ratings):\n",
    "        '''\n",
    "        Loss Function for evaluating matrix U and V\n",
    "        '''\n",
    "        errors = [\n",
    "            (float(r_ij) - np.dot(self.U[i], self.V[j].T))**2 + \\\n",
    "            self.lam * norm(self.U[i]) + self.lam * norm(self.V[j])\n",
    "            for i, j, r_ij in ratings]\n",
    "        return sum(errors)\n",
    "    \n",
    "    def mse(self, ratings):\n",
    "        \n",
    "\n",
    "    def sgd_update(self, ratings):\n",
    "        '''\n",
    "        Update matrix U and V by Stochastic Gradient Descent.\n",
    "        '''\n",
    "        for i, j, r_ij in ratings:\n",
    "            r_ij_hat = np.dot(self.U[i], self.V[j].T)\n",
    "            grad_U_i = (r_ij_hat - float(r_ij)) * self.V[j] + self.lam * self.U[i]\n",
    "            grad_V_j = (r_ij_hat - float(r_ij)) * self.U[i] + self.lam * self.V[j]\n",
    "            self.U[i] = self.U[i] - self.epsilon * grad_U_i\n",
    "            self.V[j] = self.V[j] - self.epsilon * grad_V_j\n",
    "\n",
    "    def fit(self, train_ratings, test_ratings):\n",
    "        '''\n",
    "        Fit PMF model with respect to the ratings. A rating is a triple (user,\n",
    "        item, rating), in particular, user and item are integers to indicate\n",
    "        unique ids respectively, and rating is a real value score that associates\n",
    "        with corresponding user and item. For here, ratings is a numpy array\n",
    "        with shape (n, 3).\n",
    "\n",
    "        Params:\n",
    "        - train_ratings: ratings entries for training purpose\n",
    "        - test_ratings:  ratings entries for testing purpose\n",
    "        '''\n",
    "        # get number of training samples and testing samples\n",
    "        n_trains = train_ratings.shape[0]\n",
    "        n_tests  = test_ratings.shape[0]\n",
    "        # get number of items and number of users\n",
    "        n_users  = int(max(np.amax(train_ratings[:, 0]), np.amax(test_ratings[:, 0]))) + 1\n",
    "        n_items  = int(max(np.amax(train_ratings[:, 1]), np.amax(test_ratings[:, 1]))) + 1\n",
    "        # Initialization\n",
    "        if self.V is None or self.U is None:\n",
    "            self.e = 0\n",
    "            self.U = 0.1 * np.random.randn(n_users, self.n_feature)\n",
    "            self.V = 0.1 * np.random.randn(n_items, self.n_feature)\n",
    "        # training iterations over epoches\n",
    "        while self.e < self.n_epoches:\n",
    "            self.e += 1\n",
    "            # shuffle training samples\n",
    "            shuffled_order = np.arange(n_trains)\n",
    "            np.random.shuffle(shuffled_order)\n",
    "            # training iterations over batches\n",
    "            avg_train_loss = []\n",
    "            avg_test_loss  = []\n",
    "            batch_size     = int(n_trains / self.n_batches)\n",
    "            for batch in range(self.n_batches):\n",
    "                idx       = np.arange(batch_size * batch, batch_size * (batch + 1))\n",
    "                batch_idx = np.mod(idx, n_trains).astype('int32')\n",
    "                # training ratings selected in current batch\n",
    "                batch_ratings = train_ratings[shuffled_order[batch_idx], :]\n",
    "                # test ratings sample with the same size as the training batch\n",
    "                sample_test_ratings = test_ratings[np.random.choice(n_tests, batch_size), :]\n",
    "                # update U and V by sgd in a close-formed gradient\n",
    "                self.sgd_update(batch_ratings)\n",
    "                # loss for training and testing U, V and ratings\n",
    "                train_loss = self.loss(batch_ratings)\n",
    "                test_loss  = self.loss(sample_test_ratings)\n",
    "                avg_train_loss.append(train_loss)\n",
    "                avg_test_loss.append(test_loss)\n",
    "            # training log ouput\n",
    "            avg_train_loss = np.mean(avg_train_loss) / float(batch_size)\n",
    "            avg_test_loss  = np.mean(avg_test_loss) / float(batch_size)\n",
    "            self.train_loss.append(avg_train_loss)\n",
    "            self.test_loss.append(avg_test_loss)\n",
    "            print('[%s] Epoch %d' % (arrow.now(), self.e), file=sys.stderr)\n",
    "            print('[%s] Training loss:\\t%f' % (arrow.now(), avg_train_loss), file=sys.stderr)\n",
    "            print('[%s] Testing loss:\\t%f' % (arrow.now(), avg_test_loss), file=sys.stderr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "ratingsdf = pd.read_csv('Ratings.csv')\n",
    "ratings = ratingsdf.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: (400000, 3)\n",
      "testing: (168453, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-02-19T16:09:49.270344+08:00] Epoch 1\n",
      "[2020-02-19T16:09:49.270344+08:00] Training loss:\t6.715697\n",
      "[2020-02-19T16:09:49.270344+08:00] Testing loss:\t15.398366\n",
      "[2020-02-19T16:10:08.636339+08:00] Epoch 2\n",
      "[2020-02-19T16:10:08.636339+08:00] Training loss:\t1.799436\n",
      "[2020-02-19T16:10:08.636339+08:00] Testing loss:\t12.217126\n",
      "[2020-02-19T16:10:27.760341+08:00] Epoch 3\n",
      "[2020-02-19T16:10:27.760341+08:00] Training loss:\t0.767864\n",
      "[2020-02-19T16:10:27.760341+08:00] Testing loss:\t11.884970\n",
      "[2020-02-19T16:10:46.769308+08:00] Epoch 4\n",
      "[2020-02-19T16:10:46.769308+08:00] Training loss:\t0.540073\n",
      "[2020-02-19T16:10:46.769308+08:00] Testing loss:\t11.779809\n",
      "[2020-02-19T16:11:06.419360+08:00] Epoch 5\n",
      "[2020-02-19T16:11:06.419360+08:00] Training loss:\t0.494715\n",
      "[2020-02-19T16:11:06.419360+08:00] Testing loss:\t11.731020\n",
      "[2020-02-19T16:11:25.690357+08:00] Epoch 6\n",
      "[2020-02-19T16:11:25.690357+08:00] Training loss:\t0.481588\n",
      "[2020-02-19T16:11:25.690357+08:00] Testing loss:\t11.699297\n",
      "[2020-02-19T16:11:44.787359+08:00] Epoch 7\n",
      "[2020-02-19T16:11:44.787359+08:00] Training loss:\t0.475979\n",
      "[2020-02-19T16:11:44.787359+08:00] Testing loss:\t11.605197\n",
      "[2020-02-19T16:12:04.717357+08:00] Epoch 8\n",
      "[2020-02-19T16:12:04.717357+08:00] Training loss:\t0.472460\n",
      "[2020-02-19T16:12:04.717357+08:00] Testing loss:\t11.589947\n",
      "[2020-02-19T16:12:24.197357+08:00] Epoch 9\n",
      "[2020-02-19T16:12:24.197357+08:00] Training loss:\t0.469858\n",
      "[2020-02-19T16:12:24.198359+08:00] Testing loss:\t11.561360\n",
      "[2020-02-19T16:12:43.094360+08:00] Epoch 10\n",
      "[2020-02-19T16:12:43.094360+08:00] Training loss:\t0.467781\n",
      "[2020-02-19T16:12:43.094360+08:00] Testing loss:\t11.531572\n",
      "[2020-02-19T16:13:02.344361+08:00] Epoch 11\n",
      "[2020-02-19T16:13:02.344361+08:00] Training loss:\t0.466070\n",
      "[2020-02-19T16:13:02.344361+08:00] Testing loss:\t11.497614\n",
      "[2020-02-19T16:13:21.727356+08:00] Epoch 12\n",
      "[2020-02-19T16:13:21.727356+08:00] Training loss:\t0.464417\n",
      "[2020-02-19T16:13:21.727356+08:00] Testing loss:\t11.446005\n",
      "[2020-02-19T16:13:40.891356+08:00] Epoch 13\n",
      "[2020-02-19T16:13:40.891356+08:00] Training loss:\t0.463037\n",
      "[2020-02-19T16:13:40.892358+08:00] Testing loss:\t11.417562\n",
      "[2020-02-19T16:14:00.396358+08:00] Epoch 14\n",
      "[2020-02-19T16:14:00.396358+08:00] Training loss:\t0.461781\n",
      "[2020-02-19T16:14:00.396358+08:00] Testing loss:\t11.387098\n",
      "[2020-02-19T16:14:19.874398+08:00] Epoch 15\n",
      "[2020-02-19T16:14:19.875409+08:00] Training loss:\t0.460655\n",
      "[2020-02-19T16:14:19.875409+08:00] Testing loss:\t11.396283\n",
      "[2020-02-19T16:14:39.220356+08:00] Epoch 16\n",
      "[2020-02-19T16:14:39.220356+08:00] Training loss:\t0.459559\n",
      "[2020-02-19T16:14:39.220356+08:00] Testing loss:\t11.383090\n",
      "[2020-02-19T16:14:58.346356+08:00] Epoch 17\n",
      "[2020-02-19T16:14:58.347356+08:00] Training loss:\t0.458623\n",
      "[2020-02-19T16:14:58.347356+08:00] Testing loss:\t11.333274\n",
      "[2020-02-19T16:15:17.940396+08:00] Epoch 18\n",
      "[2020-02-19T16:15:17.940396+08:00] Training loss:\t0.457628\n",
      "[2020-02-19T16:15:17.941360+08:00] Testing loss:\t11.353886\n",
      "[2020-02-19T16:15:37.421360+08:00] Epoch 19\n",
      "[2020-02-19T16:15:37.421360+08:00] Training loss:\t0.456823\n",
      "[2020-02-19T16:15:37.421360+08:00] Testing loss:\t11.290423\n",
      "[2020-02-19T16:15:56.194356+08:00] Epoch 20\n",
      "[2020-02-19T16:15:56.195359+08:00] Training loss:\t0.456015\n",
      "[2020-02-19T16:15:56.195359+08:00] Testing loss:\t11.288524\n",
      "[2020-02-19T16:16:15.651356+08:00] Epoch 21\n",
      "[2020-02-19T16:16:15.651356+08:00] Training loss:\t0.455367\n",
      "[2020-02-19T16:16:15.651356+08:00] Testing loss:\t11.240849\n",
      "[2020-02-19T16:16:34.592361+08:00] Epoch 22\n",
      "[2020-02-19T16:16:34.592361+08:00] Training loss:\t0.454655\n",
      "[2020-02-19T16:16:34.592361+08:00] Testing loss:\t11.240791\n",
      "[2020-02-19T16:16:53.528361+08:00] Epoch 23\n",
      "[2020-02-19T16:16:53.529361+08:00] Training loss:\t0.453940\n",
      "[2020-02-19T16:16:53.529361+08:00] Testing loss:\t11.207696\n",
      "[2020-02-19T16:17:13.937391+08:00] Epoch 24\n",
      "[2020-02-19T16:17:13.937391+08:00] Training loss:\t0.453344\n",
      "[2020-02-19T16:17:13.937391+08:00] Testing loss:\t11.217618\n",
      "[2020-02-19T16:17:32.683360+08:00] Epoch 25\n",
      "[2020-02-19T16:17:32.683360+08:00] Training loss:\t0.452736\n",
      "[2020-02-19T16:17:32.683360+08:00] Testing loss:\t11.159514\n",
      "[2020-02-19T16:17:51.759382+08:00] Epoch 26\n",
      "[2020-02-19T16:17:51.759382+08:00] Training loss:\t0.452180\n",
      "[2020-02-19T16:17:51.759382+08:00] Testing loss:\t11.176745\n",
      "[2020-02-19T16:18:10.866381+08:00] Epoch 27\n",
      "[2020-02-19T16:18:10.867383+08:00] Training loss:\t0.451662\n",
      "[2020-02-19T16:18:10.867383+08:00] Testing loss:\t11.163987\n",
      "[2020-02-19T16:18:32.590380+08:00] Epoch 28\n",
      "[2020-02-19T16:18:32.590380+08:00] Training loss:\t0.451134\n",
      "[2020-02-19T16:18:32.591381+08:00] Testing loss:\t11.127364\n",
      "[2020-02-19T16:18:51.709380+08:00] Epoch 29\n",
      "[2020-02-19T16:18:51.710381+08:00] Training loss:\t0.450670\n",
      "[2020-02-19T16:18:51.710381+08:00] Testing loss:\t11.150495\n",
      "[2020-02-19T16:19:10.624383+08:00] Epoch 30\n",
      "[2020-02-19T16:19:10.624383+08:00] Training loss:\t0.450271\n",
      "[2020-02-19T16:19:10.624383+08:00] Testing loss:\t11.131437\n",
      "[2020-02-19T16:19:30.172379+08:00] Epoch 31\n",
      "[2020-02-19T16:19:30.172379+08:00] Training loss:\t0.449766\n",
      "[2020-02-19T16:19:30.172379+08:00] Testing loss:\t11.080075\n",
      "[2020-02-19T16:19:49.271379+08:00] Epoch 32\n",
      "[2020-02-19T16:19:49.271379+08:00] Training loss:\t0.449331\n",
      "[2020-02-19T16:19:49.271379+08:00] Testing loss:\t11.040354\n",
      "[2020-02-19T16:20:08.507378+08:00] Epoch 33\n",
      "[2020-02-19T16:20:08.507378+08:00] Training loss:\t0.448940\n",
      "[2020-02-19T16:20:08.507378+08:00] Testing loss:\t11.041253\n",
      "[2020-02-19T16:20:27.932382+08:00] Epoch 34\n",
      "[2020-02-19T16:20:27.932382+08:00] Training loss:\t0.448496\n",
      "[2020-02-19T16:20:27.932382+08:00] Testing loss:\t11.066155\n",
      "[2020-02-19T16:20:46.884379+08:00] Epoch 35\n",
      "[2020-02-19T16:20:46.884379+08:00] Training loss:\t0.448121\n",
      "[2020-02-19T16:20:46.884379+08:00] Testing loss:\t11.023208\n",
      "[2020-02-19T16:21:05.852378+08:00] Epoch 36\n",
      "[2020-02-19T16:21:05.852378+08:00] Training loss:\t0.447771\n",
      "[2020-02-19T16:21:05.852378+08:00] Testing loss:\t11.039127\n",
      "[2020-02-19T16:21:25.400415+08:00] Epoch 37\n",
      "[2020-02-19T16:21:25.400415+08:00] Training loss:\t0.447426\n",
      "[2020-02-19T16:21:25.400415+08:00] Testing loss:\t10.996921\n",
      "[2020-02-19T16:21:44.643412+08:00] Epoch 38\n",
      "[2020-02-19T16:21:44.643412+08:00] Training loss:\t0.447065\n",
      "[2020-02-19T16:21:44.643412+08:00] Testing loss:\t10.993885\n",
      "[2020-02-19T16:22:03.602379+08:00] Epoch 39\n",
      "[2020-02-19T16:22:03.602379+08:00] Training loss:\t0.446790\n",
      "[2020-02-19T16:22:03.602379+08:00] Testing loss:\t10.977317\n",
      "[2020-02-19T16:22:22.853379+08:00] Epoch 40\n",
      "[2020-02-19T16:22:22.854384+08:00] Training loss:\t0.446441\n",
      "[2020-02-19T16:22:22.854384+08:00] Testing loss:\t10.959361\n",
      "[2020-02-19T16:22:42.309379+08:00] Epoch 41\n",
      "[2020-02-19T16:22:42.310382+08:00] Training loss:\t0.446137\n",
      "[2020-02-19T16:22:42.310382+08:00] Testing loss:\t10.974031\n",
      "[2020-02-19T16:23:01.101378+08:00] Epoch 42\n",
      "[2020-02-19T16:23:01.101378+08:00] Training loss:\t0.445811\n",
      "[2020-02-19T16:23:01.101378+08:00] Testing loss:\t10.906260\n",
      "[2020-02-19T16:23:21.060378+08:00] Epoch 43\n",
      "[2020-02-19T16:23:21.060378+08:00] Training loss:\t0.445507\n",
      "[2020-02-19T16:23:21.060378+08:00] Testing loss:\t10.895802\n",
      "[2020-02-19T16:23:40.574414+08:00] Epoch 44\n",
      "[2020-02-19T16:23:40.574414+08:00] Training loss:\t0.445255\n",
      "[2020-02-19T16:23:40.574414+08:00] Testing loss:\t10.872347\n",
      "[2020-02-19T16:23:59.696379+08:00] Epoch 45\n",
      "[2020-02-19T16:23:59.696379+08:00] Training loss:\t0.444960\n",
      "[2020-02-19T16:23:59.696379+08:00] Testing loss:\t10.920589\n",
      "[2020-02-19T16:24:18.823381+08:00] Epoch 46\n",
      "[2020-02-19T16:24:18.823381+08:00] Training loss:\t0.444668\n",
      "[2020-02-19T16:24:18.823381+08:00] Testing loss:\t10.864924\n",
      "[2020-02-19T16:24:38.089413+08:00] Epoch 47\n",
      "[2020-02-19T16:24:38.089413+08:00] Training loss:\t0.444466\n",
      "[2020-02-19T16:24:38.089413+08:00] Testing loss:\t10.888204\n",
      "[2020-02-19T16:24:57.334377+08:00] Epoch 48\n",
      "[2020-02-19T16:24:57.334377+08:00] Training loss:\t0.444171\n",
      "[2020-02-19T16:24:57.334377+08:00] Testing loss:\t10.889574\n",
      "[2020-02-19T16:25:16.361378+08:00] Epoch 49\n",
      "[2020-02-19T16:25:16.361378+08:00] Training loss:\t0.443909\n",
      "[2020-02-19T16:25:16.362380+08:00] Testing loss:\t10.853239\n",
      "[2020-02-19T16:25:35.725382+08:00] Epoch 50\n",
      "[2020-02-19T16:25:35.725382+08:00] Training loss:\t0.443703\n",
      "[2020-02-19T16:25:35.725382+08:00] Testing loss:\t10.833378\n",
      "[2020-02-19T16:25:54.644378+08:00] Epoch 51\n",
      "[2020-02-19T16:25:54.644378+08:00] Training loss:\t0.443456\n",
      "[2020-02-19T16:25:54.644378+08:00] Testing loss:\t10.806324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-02-19T16:26:13.517413+08:00] Epoch 52\n",
      "[2020-02-19T16:26:13.517413+08:00] Training loss:\t0.443243\n",
      "[2020-02-19T16:26:13.517413+08:00] Testing loss:\t10.806037\n",
      "[2020-02-19T16:26:32.811379+08:00] Epoch 53\n",
      "[2020-02-19T16:26:32.811379+08:00] Training loss:\t0.443019\n",
      "[2020-02-19T16:26:32.811379+08:00] Testing loss:\t10.808395\n",
      "[2020-02-19T16:26:52.209378+08:00] Epoch 54\n",
      "[2020-02-19T16:26:52.210379+08:00] Training loss:\t0.442780\n",
      "[2020-02-19T16:26:52.210379+08:00] Testing loss:\t10.802289\n",
      "[2020-02-19T16:27:10.989379+08:00] Epoch 55\n",
      "[2020-02-19T16:27:10.989379+08:00] Training loss:\t0.442559\n",
      "[2020-02-19T16:27:10.989379+08:00] Testing loss:\t10.779626\n",
      "[2020-02-19T16:27:29.899378+08:00] Epoch 56\n",
      "[2020-02-19T16:27:29.899378+08:00] Training loss:\t0.442341\n",
      "[2020-02-19T16:27:29.899378+08:00] Testing loss:\t10.768736\n",
      "[2020-02-19T16:27:48.935382+08:00] Epoch 57\n",
      "[2020-02-19T16:27:48.935382+08:00] Training loss:\t0.442166\n",
      "[2020-02-19T16:27:48.935382+08:00] Testing loss:\t10.767982\n",
      "[2020-02-19T16:28:08.018383+08:00] Epoch 58\n",
      "[2020-02-19T16:28:08.018383+08:00] Training loss:\t0.441942\n",
      "[2020-02-19T16:28:08.018383+08:00] Testing loss:\t10.754597\n",
      "[2020-02-19T16:28:27.433379+08:00] Epoch 59\n",
      "[2020-02-19T16:28:27.433379+08:00] Training loss:\t0.441765\n",
      "[2020-02-19T16:28:27.433379+08:00] Testing loss:\t10.754816\n",
      "[2020-02-19T16:28:46.594379+08:00] Epoch 60\n",
      "[2020-02-19T16:28:46.594379+08:00] Training loss:\t0.441545\n",
      "[2020-02-19T16:28:46.594379+08:00] Testing loss:\t10.726800\n",
      "[2020-02-19T16:29:05.691413+08:00] Epoch 61\n",
      "[2020-02-19T16:29:05.691413+08:00] Training loss:\t0.441357\n",
      "[2020-02-19T16:29:05.691413+08:00] Testing loss:\t10.695734\n",
      "[2020-02-19T16:29:24.853379+08:00] Epoch 62\n",
      "[2020-02-19T16:29:24.853379+08:00] Training loss:\t0.441183\n",
      "[2020-02-19T16:29:24.853379+08:00] Testing loss:\t10.716003\n",
      "[2020-02-19T16:29:44.258379+08:00] Epoch 63\n",
      "[2020-02-19T16:29:44.258379+08:00] Training loss:\t0.441029\n",
      "[2020-02-19T16:29:44.258379+08:00] Testing loss:\t10.717776\n",
      "[2020-02-19T16:30:03.160379+08:00] Epoch 64\n",
      "[2020-02-19T16:30:03.161379+08:00] Training loss:\t0.440914\n",
      "[2020-02-19T16:30:03.161379+08:00] Testing loss:\t10.681303\n",
      "[2020-02-19T16:30:22.196413+08:00] Epoch 65\n",
      "[2020-02-19T16:30:22.196413+08:00] Training loss:\t0.440681\n",
      "[2020-02-19T16:30:22.196413+08:00] Testing loss:\t10.668288\n",
      "[2020-02-19T16:30:41.253380+08:00] Epoch 66\n",
      "[2020-02-19T16:30:41.253380+08:00] Training loss:\t0.440503\n",
      "[2020-02-19T16:30:41.253380+08:00] Testing loss:\t10.692170\n",
      "[2020-02-19T16:31:00.441378+08:00] Epoch 67\n",
      "[2020-02-19T16:31:00.441378+08:00] Training loss:\t0.440367\n",
      "[2020-02-19T16:31:00.442380+08:00] Testing loss:\t10.664193\n",
      "[2020-02-19T16:31:19.377382+08:00] Epoch 68\n",
      "[2020-02-19T16:31:19.377382+08:00] Training loss:\t0.440158\n",
      "[2020-02-19T16:31:19.378381+08:00] Testing loss:\t10.666117\n",
      "[2020-02-19T16:31:38.394413+08:00] Epoch 69\n",
      "[2020-02-19T16:31:38.395411+08:00] Training loss:\t0.440039\n",
      "[2020-02-19T16:31:38.395411+08:00] Testing loss:\t10.644602\n",
      "[2020-02-19T16:31:57.416378+08:00] Epoch 70\n",
      "[2020-02-19T16:31:57.416378+08:00] Training loss:\t0.439872\n",
      "[2020-02-19T16:31:57.416378+08:00] Testing loss:\t10.635478\n",
      "[2020-02-19T16:32:16.509383+08:00] Epoch 71\n",
      "[2020-02-19T16:32:16.509383+08:00] Training loss:\t0.439730\n",
      "[2020-02-19T16:32:16.509383+08:00] Testing loss:\t10.624529\n",
      "[2020-02-19T16:32:35.611378+08:00] Epoch 72\n",
      "[2020-02-19T16:32:35.611378+08:00] Training loss:\t0.439587\n",
      "[2020-02-19T16:32:35.611378+08:00] Testing loss:\t10.661923\n",
      "[2020-02-19T16:32:54.945416+08:00] Epoch 73\n",
      "[2020-02-19T16:32:54.946414+08:00] Training loss:\t0.439443\n",
      "[2020-02-19T16:32:54.946414+08:00] Testing loss:\t10.577398\n",
      "[2020-02-19T16:33:14.463378+08:00] Epoch 74\n",
      "[2020-02-19T16:33:14.463378+08:00] Training loss:\t0.439294\n",
      "[2020-02-19T16:33:14.463378+08:00] Testing loss:\t10.616689\n",
      "[2020-02-19T16:33:33.579381+08:00] Epoch 75\n",
      "[2020-02-19T16:33:33.579381+08:00] Training loss:\t0.439112\n",
      "[2020-02-19T16:33:33.579381+08:00] Testing loss:\t10.600890\n",
      "[2020-02-19T16:33:52.720380+08:00] Epoch 76\n",
      "[2020-02-19T16:33:52.720380+08:00] Training loss:\t0.439001\n",
      "[2020-02-19T16:33:52.731380+08:00] Testing loss:\t10.584540\n",
      "[2020-02-19T16:34:11.697378+08:00] Epoch 77\n",
      "[2020-02-19T16:34:11.697378+08:00] Training loss:\t0.438892\n",
      "[2020-02-19T16:34:11.697378+08:00] Testing loss:\t10.573821\n",
      "[2020-02-19T16:34:30.755410+08:00] Epoch 78\n",
      "[2020-02-19T16:34:30.755410+08:00] Training loss:\t0.438696\n",
      "[2020-02-19T16:34:30.755410+08:00] Testing loss:\t10.607311\n",
      "[2020-02-19T16:34:49.994469+08:00] Epoch 79\n",
      "[2020-02-19T16:34:49.994469+08:00] Training loss:\t0.438582\n",
      "[2020-02-19T16:34:49.994469+08:00] Testing loss:\t10.546698\n",
      "[2020-02-19T16:35:09.179472+08:00] Epoch 80\n",
      "[2020-02-19T16:35:09.179472+08:00] Training loss:\t0.438433\n",
      "[2020-02-19T16:35:09.179472+08:00] Testing loss:\t10.551562\n",
      "[2020-02-19T16:35:28.197473+08:00] Epoch 81\n",
      "[2020-02-19T16:35:28.197473+08:00] Training loss:\t0.438327\n",
      "[2020-02-19T16:35:28.197473+08:00] Testing loss:\t10.570034\n",
      "[2020-02-19T16:35:47.144470+08:00] Epoch 82\n",
      "[2020-02-19T16:35:47.144470+08:00] Training loss:\t0.438207\n",
      "[2020-02-19T16:35:47.144470+08:00] Testing loss:\t10.552681\n",
      "[2020-02-19T16:36:06.375473+08:00] Epoch 83\n",
      "[2020-02-19T16:36:06.375473+08:00] Training loss:\t0.438114\n",
      "[2020-02-19T16:36:06.375473+08:00] Testing loss:\t10.522182\n",
      "[2020-02-19T16:36:25.663441+08:00] Epoch 84\n",
      "[2020-02-19T16:36:25.663441+08:00] Training loss:\t0.437982\n",
      "[2020-02-19T16:36:25.664442+08:00] Testing loss:\t10.545260\n",
      "[2020-02-19T16:36:44.499488+08:00] Epoch 85\n",
      "[2020-02-19T16:36:44.499488+08:00] Training loss:\t0.437829\n",
      "[2020-02-19T16:36:44.499488+08:00] Testing loss:\t10.526861\n",
      "[2020-02-19T16:37:03.640484+08:00] Epoch 86\n",
      "[2020-02-19T16:37:03.640484+08:00] Training loss:\t0.437749\n",
      "[2020-02-19T16:37:03.640484+08:00] Testing loss:\t10.545258\n",
      "[2020-02-19T16:37:22.721518+08:00] Epoch 87\n",
      "[2020-02-19T16:37:22.721518+08:00] Training loss:\t0.437615\n",
      "[2020-02-19T16:37:22.721518+08:00] Testing loss:\t10.488486\n",
      "[2020-02-19T16:37:41.599486+08:00] Epoch 88\n",
      "[2020-02-19T16:37:41.599486+08:00] Training loss:\t0.437495\n",
      "[2020-02-19T16:37:41.599486+08:00] Testing loss:\t10.489808\n",
      "[2020-02-19T16:38:01.012485+08:00] Epoch 89\n",
      "[2020-02-19T16:38:01.012485+08:00] Training loss:\t0.437418\n",
      "[2020-02-19T16:38:01.012485+08:00] Testing loss:\t10.497323\n",
      "[2020-02-19T16:38:20.720484+08:00] Epoch 90\n",
      "[2020-02-19T16:38:20.721485+08:00] Training loss:\t0.437292\n",
      "[2020-02-19T16:38:20.721485+08:00] Testing loss:\t10.462169\n",
      "[2020-02-19T16:38:39.831485+08:00] Epoch 91\n",
      "[2020-02-19T16:38:39.831485+08:00] Training loss:\t0.437207\n",
      "[2020-02-19T16:38:39.831485+08:00] Testing loss:\t10.469161\n",
      "[2020-02-19T16:38:59.013520+08:00] Epoch 92\n",
      "[2020-02-19T16:38:59.013520+08:00] Training loss:\t0.437046\n",
      "[2020-02-19T16:38:59.013520+08:00] Testing loss:\t10.447714\n",
      "[2020-02-19T16:39:18.391520+08:00] Epoch 93\n",
      "[2020-02-19T16:39:18.391520+08:00] Training loss:\t0.436993\n",
      "[2020-02-19T16:39:18.391520+08:00] Testing loss:\t10.508185\n",
      "[2020-02-19T16:39:37.893489+08:00] Epoch 94\n",
      "[2020-02-19T16:39:37.894489+08:00] Training loss:\t0.436917\n",
      "[2020-02-19T16:39:37.894489+08:00] Testing loss:\t10.445076\n",
      "[2020-02-19T17:45:18.644785+08:00] Epoch 95\n",
      "[2020-02-19T17:45:18.645785+08:00] Training loss:\t0.436766\n",
      "[2020-02-19T17:45:18.645785+08:00] Testing loss:\t10.452316\n",
      "[2020-02-19T17:45:42.407781+08:00] Epoch 96\n",
      "[2020-02-19T17:45:42.408783+08:00] Training loss:\t0.436719\n",
      "[2020-02-19T17:45:42.408783+08:00] Testing loss:\t10.442889\n",
      "[2020-02-19T17:46:01.533820+08:00] Epoch 97\n",
      "[2020-02-19T17:46:01.533820+08:00] Training loss:\t0.436582\n",
      "[2020-02-19T17:46:01.533820+08:00] Testing loss:\t10.444648\n",
      "[2020-02-19T17:46:21.337785+08:00] Epoch 98\n",
      "[2020-02-19T17:46:21.337785+08:00] Training loss:\t0.436508\n",
      "[2020-02-19T17:46:21.337785+08:00] Testing loss:\t10.405277\n",
      "[2020-02-19T17:46:40.111821+08:00] Epoch 99\n",
      "[2020-02-19T17:46:40.111821+08:00] Training loss:\t0.436378\n",
      "[2020-02-19T17:46:40.111821+08:00] Testing loss:\t10.401641\n",
      "[2020-02-19T17:46:59.082784+08:00] Epoch 100\n",
      "[2020-02-19T17:46:59.082784+08:00] Training loss:\t0.436328\n",
      "[2020-02-19T17:46:59.082784+08:00] Testing loss:\t10.414601\n"
     ]
    }
   ],
   "source": [
    "shuffled_order = np.arange(len(ratings))\n",
    "np.random.shuffle(shuffled_order)\n",
    "ratings        = ratings[shuffled_order]\n",
    "# cross validation\n",
    "train_ratings  = ratings[0:400000, :]\n",
    "test_ratings   = ratings[400000:, :]\n",
    "print('training:', train_ratings.shape)\n",
    "print('testing:', test_ratings.shape)\n",
    "pmf = PMF(n_feature=100, epsilon=0.1, lam=0.1, n_epoches=100, n_batches=1000)\n",
    "pmf.fit(train_ratings, test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.715696995402424, 1.7994362007913056, 0.7678638582587068, 0.5400732681462938, 0.49471528156316025, 0.4815876613819816, 0.475979146374854, 0.4724599229674437, 0.4698580049714555, 0.4677809300466813, 0.46607021907986856, 0.46441683943400003, 0.46303652082907015, 0.4617809357295318, 0.46065537856374683, 0.4595588655370513, 0.458623273575426, 0.4576276141807582, 0.45682279934470815, 0.4560154456190206, 0.45536745601392403, 0.45465489806158893, 0.4539396559321893, 0.45334426078654494, 0.45273554499643, 0.45218046609124735, 0.45166212182975934, 0.4511341736625989, 0.45067026385034964, 0.4502713631665045, 0.4497655003195945, 0.4493308672523931, 0.4489404284247638, 0.44849610872727064, 0.44812105979721034, 0.4477714547948826, 0.44742575502508297, 0.4470654525618181, 0.446789683857387, 0.44644132469797193, 0.4461374546963544, 0.44581066209862547, 0.445507214674633, 0.4452552958000979, 0.4449595742049645, 0.44466815006667604, 0.44446616461584115, 0.4441706515137899, 0.4439087383700606, 0.4437027908373322, 0.4434555735558763, 0.44324337481799625, 0.44301905693506305, 0.44277956851451816, 0.44255871475926006, 0.44234114003044583, 0.44216638878343895, 0.4419415375676753, 0.4417653412381592, 0.44154455646255886, 0.4413568307919579, 0.44118268273975636, 0.4410291134174517, 0.44091387148752736, 0.4406809722923133, 0.4405025789119785, 0.4403673591445753, 0.44015822299392576, 0.4400389390995384, 0.43987216497870757, 0.4397304867740568, 0.43958665253661655, 0.43944258165314004, 0.43929423902027787, 0.4391124883571569, 0.43900056052927844, 0.438892088179606, 0.4386964151624266, 0.43858204562452646, 0.43843272701622354, 0.43832702631110665, 0.4382066017442787, 0.4381141899182752, 0.43798241224097895, 0.4378285945041008, 0.43774946909874574, 0.4376146476449298, 0.4374952072132389, 0.43741813418137426, 0.4372916774655182, 0.43720663814221217, 0.4370458900283392, 0.4369925942432266, 0.4369172312964909, 0.43676644139915227, 0.4367189672860605, 0.436581738775728, 0.4365081867514313, 0.4363780968549387, 0.43632840949669893] [15.398366393084284, 12.217125592481564, 11.884969932407524, 11.779809049335816, 11.731019918723778, 11.699296858979837, 11.605197491513417, 11.589947379406324, 11.561360268754093, 11.531571669485498, 11.497613848237515, 11.446004848370219, 11.41756160791671, 11.387097890638405, 11.396282614866962, 11.383089501351026, 11.333274056225338, 11.35388569477562, 11.290422672342242, 11.28852369920231, 11.240849356193221, 11.240791163768424, 11.207696244434194, 11.217617831674456, 11.159514343634864, 11.176745061130012, 11.163986713408287, 11.127364224667936, 11.150494538431248, 11.131436668447112, 11.080074820324853, 11.040354034192985, 11.041252638841522, 11.06615458658412, 11.023207948318738, 11.039126929367981, 10.99692076682419, 10.993885257019832, 10.977316805608677, 10.95936054299553, 10.97403100576632, 10.90625986688948, 10.895802075451522, 10.872346943815108, 10.920589375592895, 10.86492392669674, 10.88820439940313, 10.889574225394963, 10.853239454310232, 10.833377786037682, 10.806324287386172, 10.806036638766988, 10.808395137557195, 10.802289482362045, 10.779625805726809, 10.768736262303399, 10.76798195534057, 10.754597334653395, 10.754815683419045, 10.726799533321605, 10.695734271170807, 10.716002611119455, 10.717776380643736, 10.681302519980663, 10.668287733254566, 10.692170296169344, 10.6641932761932, 10.666117430653326, 10.644602260988284, 10.635478288609455, 10.62452939537657, 10.661923006064837, 10.57739848688477, 10.616689245661895, 10.600889528876905, 10.58454017849899, 10.573821281444006, 10.607311426775404, 10.546697560795238, 10.551561793459365, 10.570034320090906, 10.552681110546702, 10.52218185271923, 10.54526037192644, 10.526860782900195, 10.545257621870899, 10.488485853341398, 10.489807989682447, 10.497323468174637, 10.462168988820817, 10.469161164616393, 10.447713724930871, 10.508185335423077, 10.445075971190567, 10.45231590873836, 10.44288926814345, 10.444648318505173, 10.405276992614104, 10.401641132853719, 10.414600522561589]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(pmf.train_loss, pmf.test_loss)\n",
    "plt.plot(pmf.train_loss)\n",
    "plt.plot(pmf.test_loss)\n",
    "\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
